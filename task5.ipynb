{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a47c52c0-aeb0-441e-aae8-d5ae36620bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ollama langchain llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77bf92de-e1f2-41fe-b43c-ae1376ae925e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.12/site-packages (0.3.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.10 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (0.3.10)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (0.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (0.1.132)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.32.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (4.11.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain) (2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9589ba1b-8c87-425f-affe-eb922154bdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.3.3\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/anaconda3/lib/python3.12/site-packages\n",
      "Requires: aiohttp, langchain-core, langchain-text-splitters, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: langchain-community\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff3800ca-9b9b-45d1-bbd2-8c97dbcfaeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Any', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__getattr__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_module_lookup', 'create_importer', 'importer']\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(dir(langchain.chains))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e25616f-c8aa-4949-bf66-c049cc45707e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask your question, or type 'exit'  what the  10 top move now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x6/kzmpq__n0ld4183mgxkld8s80000gn/T/ipykernel_1775/2418569530.py:9: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  answer = llm(prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the current top 10 movies (as of my knowledge cutoff in December 2023), based on their critical and commercial success:\n",
      "\n",
      "1. **Oppenheimer** (Biographical Drama) - Directed by Christopher Nolan, starring Cillian Murphy\n",
      "2. **Barbie** (Comedy-Fantasy) - Directed by Greta Gerwig, starring Margot Robbie\n",
      "3. **The Little Mermaid** (Musical Fantasy) - Directed by Rob Marshall, starring Halle Bailey\n",
      "4. **Spider-Man: Across the Spider-Verse** (Animated Superhero) - Directed by Joaquim Dos Santos and Kemp Powers\n",
      "5. **Top Gun: Maverick** (Action Drama) - Directed by Joseph Kosinski, starring Tom Cruise\n",
      "6. **Guardians of the Galaxy Vol. 3** (Superhero Adventure) - Directed by James Gunn, starring Chris Pratt\n",
      "7. **Dune: Part Two** (Science Fiction Epic) - Directed by Denis Villeneuve, starring Timothée Chalamet\n",
      "8. **The Batman** (Superhero Thriller) - Directed by Matt Reeves, starring Robert Pattinson\n",
      "9. **Wonka** (Fantasy Comedy-Drama) - Directed by Paul King, starring Timothée Chalamet\n",
      "10. **Avatar: The Way of Water** (Science Fiction Epic) - Directed by James Cameron, starring Sam Worthington\n",
      "\n",
      "Note that this is not an exhaustive or definitive list, and the ranking may vary based on individual opinions and preferences.\n",
      "\n",
      "Also, keep in mind that new movies are being released regularly, so this list might change over time. If you're looking for more information or want to know about newer releases, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "            from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "            llm = OllamaLLM(model=\"llama3.2\",model_kwargs={\"temperature\": 1, \"max_tokens\": 200})\n",
    "            while True:\n",
    "                prompt = input(\"Ask your question, or type 'exit' \")\n",
    "                if prompt.lower() == \"exit\":\n",
    "                    print(\"Exit\")\n",
    "                    break\n",
    "                answer = llm(prompt)\n",
    "                print(answer)\n",
    "\n",
    "            from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "            # 01 Initialize the Ollama LLM\n",
    "            llm = OllamaLLM(model=\"llama3.2\")  #model=\"llama3.2\", model=\"deepseek-coder-v2\", model=\"qwen2\"\n",
    "\n",
    "            # Make a request to the model\n",
    "            response = llm(\"please find the 10 germany movies in historz, return data as json\")\n",
    "            print(response)\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            #  part 2\n",
    "            from llama_index.llms.ollama import Ollama\n",
    "            from llama_index.core.llms import ChatMessage\n",
    "\n",
    "            llm = Ollama(model=\"llama3.2\",model_kwargs={\"temperature\": 1, \"max_tokens\": 200})\n",
    "            messages = [ ChatMessage(role=\"user\", content= prompt)]\n",
    "            while True:\n",
    "                prompt = input(\"Ask your question, or type 'exit' \")\n",
    "                if prompt.lower() == \"exit\":\n",
    "                    print(\"Exit\")\n",
    "                    break\n",
    "                answer = llm.chat(messages)\n",
    "                print(answer)\n",
    "\n",
    "            from llama_index.llms.ollama import Ollama\n",
    "            from llama_index.core.llms import ChatMessage\n",
    "\n",
    "            # Initialize the LLM\n",
    "            llm = Ollama(model=\"llama3.2\", model_kwargs={\"temperature\": 1, \"max_tokens\": 200})\n",
    "\n",
    "            while True:\n",
    "                prompt = input(\"Ask your question, or type 'exit': \")\n",
    "                if prompt.lower() == \"exit\":\n",
    "                    print(\"Exit\")\n",
    "                    break\n",
    "                \n",
    "                # Add the user message to the messages list\n",
    "                messages = [(ChatMessage(role=\"user\", content=prompt))]\n",
    "                \n",
    "                # Get the answer from the LLM\n",
    "                answer = llm.chat(messages)\n",
    "                print(answer)\n",
    "            \n",
    "\n",
    "            ### Chat Streaming \n",
    "            from llama_index.llms.ollama import Ollama\n",
    "            from llama_index.core.llms import ChatMessage\n",
    "\n",
    "            # Initialize the model\n",
    "            llm = Ollama(model=\"llama3.2\")\n",
    "\n",
    "            messages = [\n",
    "                ChatMessage(\n",
    "                    role=\"system\", content=\"You are helpful assistant to create programs\"\n",
    "                ),\n",
    "                ChatMessage(role=\"user\", content=\"Write a python program to calculate the fact of numbers\"),\n",
    "            ]\n",
    "\n",
    "            response = llm.stream_chat(messages)\n",
    "            for r in response:\n",
    "                print(r.delta, end=\"\")\n",
    "                \n",
    "\n",
    "            from llama_index.llms.ollama import Ollama\n",
    "            from llama_index.core.llms import ChatMessage\n",
    "\n",
    "            # Initialize the model\n",
    "            llm = Ollama(model=\"llama3.2\")\n",
    "\n",
    "            messages = [\n",
    "             #   ChatMessage(\n",
    "              #      role=\"system\", content=\"You are helpful assistant to create programs\"\n",
    "             #   ),\n",
    "                ChatMessage(role=\"user\", content=\"please find the 10 germany movies from 2000, return data as json\"),\n",
    "            ]\n",
    "\n",
    "            response = llm.chat(messages)\n",
    "            print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371ebcee-1148-4eef-aecb-5ef60ac16dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
